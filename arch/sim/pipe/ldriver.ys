#######################################################################
# Test for copying block of size 63;
#######################################################################
	.pos 0
main:	irmovq Stack, %rsp  	# Set up stack pointer

	# Set up arguments for copy function and then invoke it
	irmovq $63, %rdx		# src and dst have 63 elements
	irmovq dest, %rsi	# dst array
	irmovq src, %rdi	# src array
	call ncopy		 
	halt			# should halt with num nonzeros in %rax
StartFun:
#/* $begin ncopy-ys */
##################################################################
# ncopy.ys - Copy a src block of len words to dst.
# Return the number of positive words (>0) contained in src.
#
# Include your name and ID here.
#
# Describe how and why you modified the baseline code.
#
##################################################################
# Do not modify this portion
# Function prologue.
# %rdi = src, %rsi = dst, %rdx = len
ncopy:

##################################################################
# You can modify this portion
	# Loop header
	iaddq $-9,%rdx
	andq %rdx,%rdx		# len <= 0?
	jl Symbol	# if so, goto Done:

Loop:	mrmovq (%rdi), %r8	# read val from src...
	mrmovq 8(%rdi),%r9
	mrmovq 16(%rdi),%r10
	mrmovq 24(%rdi),%r11
	mrmovq 32(%rdi),%r12
	mrmovq 40(%rdi),%r13
	mrmovq 48(%rdi),%r14
	mrmovq 56(%rdi),%rcx
	mrmovq 64(%rdi),%rbx
	rmmovq %r8,(%rsi)
	rmmovq %r9,8(%rsi)
	rmmovq %r10,16(%rsi)
	rmmovq %r11,24(%rsi)
	rmmovq %r12,32(%rsi)
	rmmovq %r13,40(%rsi)
	rmmovq %r14,48(%rsi)
	rmmovq %rcx,56(%rsi)
	rmmovq %rbx,64(%rsi)
Loop1:	andq %r8,%r8
	jle Loop2
	iaddq $1,%rax
Loop2:	andq %r9, %r9		# val <= 0?
	jle Loop3		# if so, goto Npos:
	iaddq $1, %rax		# count++
Loop3:	andq %r10,%r10
        jle Loop4
        iaddq $1,%rax
Loop4:  andq %r11,%r11
        jle Loop5
        iaddq $1,%rax
Loop5:	andq %r12,%r12
        jle Loop6
        iaddq $1,%rax
Loop6: 	andq %r13,%r13
        jle Loop7
        iaddq $1,%rax
Loop7:  andq %r14,%r14
        jle Loop8
        iaddq $1,%rax
Loop8:  andq %rcx,%rcx
        jle Loop9
        iaddq $1,%rax
Loop9:  andq %rbx,%rbx
        jle Npos
        iaddq $1,%rax
Npos:	iaddq $72, %rdi		# src++
	iaddq $72, %rsi		# dst++
	iaddq $-9,%rdx
	jge Loop			# if so, goto Loop:
Symbol:	iaddq $6,%rdx
	jg right
	je rloop3
left:	iaddq $2,%rdx
	jl Done
	je rloop1
	iaddq $-1,%rdx
	je rloop2
right:	iaddq $-3,%rdx
	jl lt
	je rloop6
rt:	iaddq $-2,%rdx
	jl rloop7
	je rloop8
lt:	iaddq $1,%rdx
	je rloop5
	jmp rloop4
rloop8: mrmovq 56(%rdi),%r8
	andq %r8,%r8
	rmmovq %r8,56(%rsi)
rloop7: mrmovq 48(%rdi),%r8
        jle rloop72
        iaddq $1,%rax
rloop72:rmmovq %r8,48(%rsi)
        andq %r8,%r8
rloop6: mrmovq 40(%rdi),%r8
        jle rloop62
        iaddq $1,%rax
rloop62:rmmovq %r8,40(%rsi)
        andq %r8,%r8
rloop5: mrmovq 32(%rdi),%r8
        jle rloop52
        iaddq $1,%rax
rloop52:rmmovq %r8,32(%rsi)
        andq %r8,%r8
rloop4:	mrmovq 24(%rdi),%r8
	jle rloop42
	iaddq $1,%rax
rloop42:rmmovq %r8,24(%rsi)
	andq %r8,%r8
rloop3: mrmovq 16(%rdi),%r8
        jle rloop32
        iaddq $1,%rax
rloop32:rmmovq %r8,16(%rsi)
        andq %r8,%r8
rloop2: mrmovq 8(%rdi),%r8
        jle rloop22
        iaddq $1,%rax
rloop22:rmmovq %r8,8(%rsi)
        andq %r8,%r8
rloop1: mrmovq (%rdi),%r8
        jle rloop12
        iaddq $1,%rax
rloop12:rmmovq %r8,(%rsi)
        andq %r8,%r8
	jle Done
	iaddq $1,%rax
#remain:	mrmovq (%rdi),%r10
#	rmmovq %r10,(%rsi)
#	iaddq $8,%rdi
#	iaddq $8,%rsi
#	andq %r10,%r10
#	jle Rloop
#	iaddq $1,%rax
#Rloop:	iaddq $-1,%rdx
#	jge remain
##################################################################
# Do not modify the following section of code
# Function epilogue.
Done:
	ret
##################################################################
# Keep the following label at the end of your function
End:
#/* $end ncopy-ys */
EndFun:

###############################
# Source and destination blocks 
###############################
	.align 8
src:
	.quad 1
	.quad -2
	.quad 3
	.quad -4
	.quad -5
	.quad -6
	.quad 7
	.quad 8
	.quad 9
	.quad -10
	.quad 11
	.quad 12
	.quad 13
	.quad -14
	.quad -15
	.quad -16
	.quad 17
	.quad -18
	.quad 19
	.quad 20
	.quad -21
	.quad -22
	.quad 23
	.quad 24
	.quad -25
	.quad 26
	.quad 27
	.quad -28
	.quad -29
	.quad 30
	.quad 31
	.quad 32
	.quad 33
	.quad -34
	.quad 35
	.quad -36
	.quad -37
	.quad -38
	.quad -39
	.quad 40
	.quad 41
	.quad 42
	.quad 43
	.quad -44
	.quad -45
	.quad 46
	.quad -47
	.quad -48
	.quad -49
	.quad 50
	.quad -51
	.quad 52
	.quad 53
	.quad 54
	.quad 55
	.quad -56
	.quad 57
	.quad -58
	.quad -59
	.quad -60
	.quad -61
	.quad -62
	.quad -63
	.quad 0xbcdefa # This shouldn't get moved

	.align 16
Predest:
	.quad 0xbcdefa
dest:
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
Postdest:
	.quad 0xdefabc

.align 8
# Run time stack
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0

Stack:
